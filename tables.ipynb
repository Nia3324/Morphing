{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{tabular}{l c c c}\n",
      "\\toprule\n",
      "\\textbf{Dataset} & \\textbf{Train Shape} & \\textbf{Test Shape} & \\textbf{\\# Classes} \\\\\n",
      "\\midrule\n",
      "AtrialFibrillation (AF) & (19, 2, 640) & (5, 2, 640) & 3 \\\\\n",
      "CinCECGTorso (CET) & (908, 1, 1639) & (228, 1, 1639) & 4 \\\\\n",
      "Colposcopy (COL) & (128, 1, 180) & (32, 1, 180) & 6 \\\\\n",
      "ECG200 (ECG) & (128, 1, 96) & (32, 1, 96) & 2 \\\\\n",
      "ECG5000 (ECG5) & (3200, 1, 140) & (800, 1, 140) & 5 \\\\\n",
      "EMOPain (EMO) & (846, 30, 200) & (212, 30, 200) & 3 \\\\\n",
      "EOGHorizontalSignal (EOGH) & (463, 1, 1250) & (116, 1, 1250) & 12 \\\\\n",
      "EOGVerticalSignal (EOGV) & (463, 1, 1250) & (116, 1, 1250) & 12 \\\\\n",
      "Epilepsy (EPI) & (176, 3, 206) & (44, 3, 206) & 4 \\\\\n",
      "EyesOpenShut (EOS) & (62, 14, 128) & (16, 14, 128) & 2 \\\\\n",
      "HandMovementDirection (HMD) & (149, 10, 400) & (38, 10, 400) & 4 \\\\\n",
      "Heartbeat (HRT) & (261, 61, 405) & (66, 61, 405) & 2 \\\\\n",
      "MedicalImages (MI) & (729, 1, 99) & (183, 1, 99) & 10 \\\\\n",
      "NerveDamage (ND) & (130, 1, 1500) & (33, 1, 1500) & 3 \\\\\n",
      "ToeSegmentation1 (TOE) & (171, 1, 277) & (43, 1, 277) & 2 \\\\\n",
      "TwoLeadECG (TECG) & (743, 1, 82) & (186, 1, 82) & 2 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('results/final_results.csv')\n",
    "\n",
    "# Define mappings for shortening dataset names\n",
    "dataset_mapping = {\n",
    "    \"AtrialFibrillation\": \"AF\",\n",
    "    \"CinCECGTorso\": \"CET\",\n",
    "    \"Colposcopy\": \"COL\",\n",
    "    \"ECG200\": \"ECG\",\n",
    "    \"ECG5000\": \"ECG5\",\n",
    "    \"EOGHorizontalSignal\": \"EOGH\",\n",
    "    \"EOGVerticalSignal\": \"EOGV\",\n",
    "    \"EMOPain\": \"EMO\",\n",
    "    \"Epilepsy\": \"EPI\",\n",
    "    \"EyesOpenShut\": \"EOS\",\n",
    "    \"HandMovementDirection\": \"HMD\",\n",
    "    \"Heartbeat\": \"HRT\",\n",
    "    \"MedicalImages\": \"MI\",\n",
    "    \"NerveDamage\": \"ND\",\n",
    "    \"ToeSegmentation1\": \"TOE\",\n",
    "    \"TwoLeadECG\": \"TECG\"\n",
    "}\n",
    "\n",
    "# Group by dataset to get unique datasets\n",
    "grouped = df.groupby('dataset').first().reset_index()\n",
    "\n",
    "# Initialize a list to store table rows\n",
    "table_rows = []\n",
    "\n",
    "# Iterate over each dataset\n",
    "for _, row in grouped.iterrows():\n",
    "    dataset_name = row['dataset']\n",
    "    # Add the shortened name in parentheses\n",
    "    shortened_name = dataset_mapping.get(dataset_name, dataset_name)  # Use original name if no mapping exists\n",
    "    dataset_name_formatted = f\"{dataset_name} ({shortened_name})\"\n",
    "    \n",
    "    n_variates = int(row['n_variates'])  # Number of variates (e.g., 1 for univariate)\n",
    "    ts_length = int(row['ts_length'])    # Time series length\n",
    "    n_classes = int(row['n_classes'])    # Number of classes\n",
    "    \n",
    "    # Calculate train and test sizes (80/20 split)\n",
    "    total_samples = int(row['df_size'])\n",
    "    train_size = int(total_samples * 0.8)\n",
    "    test_size = total_samples - train_size\n",
    "    \n",
    "    # Format train and test shapes\n",
    "    train_shape = f\"({train_size}, {n_variates}, {ts_length})\"\n",
    "    test_shape = f\"({test_size}, {n_variates}, {ts_length})\"\n",
    "    \n",
    "    # Append to table rows\n",
    "    table_rows.append([dataset_name_formatted, train_shape, test_shape, n_classes])\n",
    "\n",
    "# Generate the LaTeX table\n",
    "latex_table = \"\"\"\n",
    "\\\\begin{tabular}{l c c c}\n",
    "\\\\toprule\n",
    "\\\\textbf{Dataset} & \\\\textbf{Train Shape} & \\\\textbf{Test Shape} & \\\\textbf{\\\\# Classes} \\\\\\\\\n",
    "\\\\midrule\n",
    "\"\"\"\n",
    "\n",
    "# Add rows to the table\n",
    "for row in table_rows:\n",
    "    latex_table += f\"{row[0]} & {row[1]} & {row[2]} & {row[3]} \\\\\\\\\\n\"\n",
    "\n",
    "# Close the table\n",
    "latex_table += \"\"\"\\\\bottomrule\n",
    "\\\\end{tabular}\n",
    "\"\"\"\n",
    "\n",
    "# Print the LaTeX table\n",
    "print(latex_table)\n",
    "\n",
    "# Optionally, save the table to a .tex file\n",
    "with open('dataset_table.tex', 'w') as f:\n",
    "    f.write(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(['n', 's', 't'], dtype='<U1'), array([10, 10, 10], dtype=int64))\n",
      "(30, 2, 640)\n",
      "[[-0.02964  0.00988  0.00988 ... -0.13832 -0.15314 -0.1482 ]\n",
      " [ 0.      -0.00988 -0.02964 ...  0.08892  0.0988   0.0988 ]]\n",
      "[[ 0.66445  1.1645   1.0001  ... -0.0411  -0.1918  -0.1233 ]\n",
      " [ 0.02684  0.08723 -0.16775 ...  0.01342 -0.00671  0.00671]]\n",
      "[[ 0.07686  0.06588  0.02196 ... -0.08784 -0.09333 -0.07137]\n",
      " [ 0.1309   0.1309   0.0952  ... -0.05355 -0.04165 -0.01785]]\n",
      "[[-0.2091  -0.2091  -0.204   ... -0.1938  -0.4131  -0.4233 ]\n",
      " [ 0.01104 -0.00552  0.      ... -0.02208  0.03312  0.11592]]\n",
      "[[-0.01482 -0.03458 -0.03458 ...  0.0494   0.13832  0.08398]\n",
      " [ 0.01482  0.01482  0.00494 ... -0.03952 -0.02964  0.00988]]\n",
      "[[-0.15314 -0.10374 -0.0494  ... -0.1482  -0.13338 -0.12844]\n",
      " [ 0.00988  0.01482  0.04446 ...  0.15314  0.0988   0.03952]]\n",
      "[[-0.05391 -0.06589 -0.08386 ...  0.09584  0.11381  0.09584]\n",
      " [ 0.27166  0.30056  0.3179  ...  0.15028  0.2023   0.2312 ]]\n",
      "[[ 0.12844  0.12844  0.16302 ... -0.10868 -0.09386 -0.08398]\n",
      " [ 0.05928  0.05928  0.0494  ...  0.08892  0.10374  0.11362]]\n",
      "[[-0.08398 -0.08398 -0.06916 ... -0.06422 -0.0494  -0.01482]\n",
      " [-0.01482  0.      -0.02964 ...  0.01976  0.00494  0.01482]]\n",
      "[[-0.05928 -0.04446 -0.05434 ... -0.10868 -0.10868 -0.09386]\n",
      " [ 0.00988  0.00494  0.00988 ...  0.03458  0.03952  0.03458]]\n",
      "----------------------------------------------------------------------\n",
      "[[-0.1235  -0.11856 -0.13832 ...  0.10374  0.12844  0.15314]\n",
      " [ 0.11362  0.11362  0.10374 ...  0.01482  0.01482  0.00988]]\n",
      "[[ 0.05434  0.00988  0.03952 ... -0.04446 -0.10868 -0.06916]\n",
      " [ 0.00988  0.01976  0.00988 ...  0.01976  0.00988  0.00494]]\n",
      "[[ 0.02964 -0.06916 -0.10374 ... -0.07904 -0.16796 -0.03458]\n",
      " [ 0.18278  0.12844  0.10374 ...  0.02964  0.0247   0.0247 ]]\n",
      "[[ 0.22762  0.29351  0.20366 ... -0.25158 -0.02995  0.2396 ]\n",
      " [-0.93636 -0.4335  -0.13294 ... -2.0114  -2.023   -1.1155 ]]\n",
      "[[-0.0741  -0.04446 -0.07904 ... -0.06916 -0.06916 -0.07904]\n",
      " [ 0.06422  0.06916  0.0494  ...  0.09386  0.08398  0.08892]]\n",
      "[[ 0.00988  0.       0.00988 ...  0.10868  0.42484  0.71136]\n",
      " [-0.01482 -0.01482 -0.02964 ... -0.04446 -0.16302 -0.15808]]\n",
      "[[-0.1224  -0.1326  -0.1326  ... -0.1479  -0.1428  -0.1428 ]\n",
      " [-0.01104 -0.0276   0.01104 ... -0.03864 -0.04416 -0.06072]]\n",
      "[[-0.03425 -0.03425 -0.02055 ... -0.0274  -0.0137  -0.0274 ]\n",
      " [-0.04026 -0.03355 -0.04026 ... -0.00671 -0.00671  0.00671]]\n",
      "[[-0.10868 -0.11856 -0.16302 ... -0.08892 -0.08398 -0.0988 ]\n",
      " [ 0.05434  0.05928  0.06422 ...  0.08892  0.09386  0.07904]]\n",
      "[[-0.07137 -0.01647 -0.01098 ...  0.07137  0.04392  0.     ]\n",
      " [ 0.10115  0.08925  0.08925 ...  0.05355  0.0238   0.01785]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from aeon.datasets import load_classification\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = 'AtrialFibrillation'\n",
    "X, y = load_classification(data)\n",
    "\n",
    "print(np.unique(y, return_counts=True))\n",
    "print(X.shape)\n",
    "\n",
    "for x in X[y=='s']:\n",
    "    print(x)\n",
    "\n",
    "\n",
    "print(\"-\"*70)\n",
    "\n",
    "for x in X[y=='t']:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\textbf{AF}\n",
      "& n (33\\%) & 0.0 & - & 0.0 & 0.0 & - & 0.333 & 0.0 & - & 0.0 \\\\\n",
      "& s (29\\%) & 0.0 & - & 0.0 & 0.0 & - & 0.333 & 0.0 & - & 0.0 \\\\\n",
      "& t (37\\%) & 0.0 & - & 0.0 & 0.0 & - & 0.333 & 0.0 & - & 0.0 \\\\\n",
      "\\textbf{CET}\n",
      "& 1 (24\\%) & 0.575 & 0.134 & 0.996 & 0.571 & 0.15 & 0.979 & 0.563 & 0.061 & 1.0 \\\\\n",
      "& 2 (25\\%) & 0.474 & 0.136 & 0.996 & 0.424 & 0.137 & 0.979 & 0.483 & 0.067 & 1.0 \\\\\n",
      "& 3 (25\\%) & 0.524 & 0.085 & 0.996 & 0.489 & 0.14 & 0.979 & 0.518 & 0.065 & 1.0 \\\\\n",
      "& 4 (24\\%) & 0.447 & 0.104 & 0.996 & 0.417 & 0.177 & 0.979 & 0.469 & 0.094 & 1.0 \\\\\n",
      "\\textbf{COL}\n",
      "& 0 (8\\%) & 0.0 & - & 0.45 & 0.0 & - & 0.425 & 0.0 & - & 0.3 \\\\\n",
      "& 1 (11\\%) & 0.0 & - & 0.45 & 0.0 & - & 0.425 & 0.0 & - & 0.3 \\\\\n",
      "& 2 (10\\%) & 0.0 & - & 0.45 & 0.274 & 0.348 & 0.425 & 0.0 & - & 0.3 \\\\\n",
      "& 3 (25\\%) & 0.0 & - & 0.45 & 0.0 & - & 0.425 & 0.0 & - & 0.3 \\\\\n",
      "& 4 (15\\%) & 0.0 & - & 0.45 & 0.785 & 0.055 & 0.425 & 0.32 & - & 0.3 \\\\\n",
      "& 5 (28\\%) & 0.43 & 0.164 & 0.45 & 0.078 & 0.066 & 0.425 & 0.67 & 0.172 & 0.3 \\\\\n",
      "\\textbf{ECG}\n",
      "& -1 (33\\%) & 0.407 & 0.081 & 0.85 & 0.336 & 0.126 & 0.8 & 0.392 & 0.125 & 0.95 \\\\\n",
      "& 1 (66\\%) & 0.633 & 0.081 & 0.85 & 0.614 & 0.163 & 0.8 & 0.648 & 0.125 & 0.95 \\\\\n",
      "\\textbf{ECG5}\n",
      "& 1 (58\\%) & 0.358 & 0.173 & 0.956 & 0.338 & 0.164 & 0.948 & 0.279 & 0.123 & 0.963 \\\\\n",
      "& 2 (35\\%) & 0.202 & 0.208 & 0.956 & 0.396 & 0.261 & 0.948 & 0.278 & 0.212 & 0.963 \\\\\n",
      "& 3 (1\\%) & 0.822 & 0.112 & 0.956 & 0.533 & 0.098 & 0.948 & 0.776 & 0.129 & 0.963 \\\\\n",
      "& 4 (3\\%) & 0.695 & 0.145 & 0.956 & 0.285 & 0.066 & 0.948 & 0.767 & 0.236 & 0.963 \\\\\n",
      "& 5 (0\\%) & 0.0 & - & 0.956 & 0.0 & - & 0.948 & 0.0 & - & 0.963 \\\\\n",
      "\\textbf{EMO}\n",
      "& 0 (77\\%) & 0.057 & 0.017 & 0.777 & 0.148 & 0.122 & 0.906 & 0.633 & 0.394 & 0.789 \\\\\n",
      "& 1 (14\\%) & 0.535 & 0.022 & 0.777 & 0.67 & 0.203 & 0.906 & 0.269 & 0.298 & 0.789 \\\\\n",
      "& 2 (8\\%) & 0.909 & 0.039 & 0.777 & 0.869 & 0.163 & 0.906 & 0.0 & - & 0.789 \\\\\n",
      "\\textbf{EOGH}\n",
      "& 1 (9\\%) & 0.0 & - & 0.262 & 0.355 & 0.259 & 0.786 & 0.406 & 0.192 & 0.89 \\\\\n",
      "& 10 (7\\%) & 0.0 & - & 0.262 & 0.289 & 0.185 & 0.786 & 0.393 & 0.194 & 0.89 \\\\\n",
      "& 11 (8\\%) & 0.573 & 0.337 & 0.262 & 0.412 & 0.195 & 0.786 & 0.539 & 0.186 & 0.89 \\\\\n",
      "& 12 (7\\%) & 0.0 & - & 0.262 & 0.417 & 0.239 & 0.786 & 0.518 & 0.231 & 0.89 \\\\\n",
      "& 2 (8\\%) & 0.0 & - & 0.262 & 0.498 & 0.286 & 0.786 & 0.655 & 0.235 & 0.89 \\\\\n",
      "& 3 (8\\%) & 0.621 & 0.32 & 0.262 & 0.359 & 0.226 & 0.786 & 0.44 & 0.171 & 0.89 \\\\\n",
      "& 4 (8\\%) & 0.0 & - & 0.262 & 0.348 & 0.23 & 0.786 & 0.406 & 0.211 & 0.89 \\\\\n",
      "& 5 (9\\%) & 0.0 & - & 0.262 & 0.286 & 0.197 & 0.786 & 0.433 & 0.219 & 0.89 \\\\\n",
      "& 6 (8\\%) & 0.344 & 0.138 & 0.262 & 0.258 & 0.19 & 0.786 & 0.379 & 0.19 & 0.89 \\\\\n",
      "& 7 (7\\%) & 0.262 & 0.273 & 0.262 & 0.414 & 0.244 & 0.786 & 0.473 & 0.183 & 0.89 \\\\\n",
      "& 8 (6\\%) & 0.0 & - & 0.262 & 0.295 & 0.247 & 0.786 & 0.323 & 0.162 & 0.89 \\\\\n",
      "& 9 (8\\%) & 0.0 & - & 0.262 & 0.298 & 0.196 & 0.786 & 0.389 & 0.215 & 0.89 \\\\\n",
      "\\textbf{EOGV}\n",
      "& 1 (9\\%) & 0.0 & - & 0.207 & 0.515 & 0.276 & 0.662 & 0.736 & 0.164 & 0.828 \\\\\n",
      "& 10 (7\\%) & 0.03 & - & 0.207 & 0.24 & 0.184 & 0.662 & 0.343 & 0.162 & 0.828 \\\\\n",
      "& 11 (8\\%) & 0.26 & 0.24 & 0.207 & 0.373 & 0.292 & 0.662 & 0.42 & 0.164 & 0.828 \\\\\n",
      "& 12 (7\\%) & 0.0 & - & 0.207 & 0.369 & 0.231 & 0.662 & 0.4 & 0.184 & 0.828 \\\\\n",
      "& 2 (8\\%) & 0.0 & - & 0.207 & 0.342 & 0.256 & 0.662 & 0.496 & 0.232 & 0.828 \\\\\n",
      "& 3 (8\\%) & 0.0 & - & 0.207 & 0.374 & 0.226 & 0.662 & 0.428 & 0.18 & 0.828 \\\\\n",
      "& 4 (8\\%) & 0.0 & - & 0.207 & 0.292 & 0.237 & 0.662 & 0.462 & 0.21 & 0.828 \\\\\n",
      "& 5 (9\\%) & 0.255 & 0.205 & 0.207 & 0.275 & 0.166 & 0.662 & 0.406 & 0.171 & 0.828 \\\\\n",
      "& 6 (8\\%) & 0.0 & - & 0.207 & 0.313 & 0.234 & 0.662 & 0.515 & 0.17 & 0.828 \\\\\n",
      "& 7 (7\\%) & 0.342 & 0.252 & 0.207 & 0.322 & 0.232 & 0.662 & 0.478 & 0.179 & 0.828 \\\\\n",
      "& 8 (6\\%) & 0.0 & - & 0.207 & 0.32 & 0.227 & 0.662 & 0.36 & 0.138 & 0.828 \\\\\n",
      "& 9 (8\\%) & 0.16 & 0.131 & 0.207 & 0.322 & 0.246 & 0.662 & 0.419 & 0.176 & 0.828 \\\\\n",
      "\\textbf{EOS}\n",
      "& 0 (55\\%) & 0.0 & - & 0.55 & 0.111 & 0.185 & 0.65 & 0.43 & 0.106 & 0.5 \\\\\n",
      "& 1 (44\\%) & 0.0 & - & 0.55 & 0.829 & 0.163 & 0.65 & 0.61 & 0.106 & 0.5 \\\\\n",
      "\\textbf{EPI}\n",
      "& epilepsy (24\\%) & 0.662 & 0.176 & 0.764 & 0.565 & 0.156 & 0.982 & 0.498 & 0.211 & 0.982 \\\\\n",
      "& running (26\\%) & 0.488 & 0.162 & 0.764 & 0.403 & 0.191 & 0.982 & 0.317 & 0.072 & 0.982 \\\\\n",
      "& sawing (21\\%) & 0.382 & 0.151 & 0.764 & 0.371 & 0.153 & 0.982 & 0.488 & 0.158 & 0.982 \\\\\n",
      "& walking (27\\%) & 0.456 & 0.238 & 0.764 & 0.419 & 0.173 & 0.982 & 0.542 & 0.195 & 0.982 \\\\\n",
      "\\textbf{HMD}\n",
      "& backward (22\\%) & 0.04 & - & 0.255 & 0.0 & - & 0.319 & 0.58 & - & 0.383 \\\\\n",
      "& forward (31\\%) & 0.332 & 0.387 & 0.255 & 0.2 & - & 0.319 & 0.4 & 0.176 & 0.383 \\\\\n",
      "& left (24\\%) & 0.259 & 0.225 & 0.255 & 0.127 & 0.165 & 0.319 & 0.338 & 0.231 & 0.383 \\\\\n",
      "& right (22\\%) & 0.386 & 0.36 & 0.255 & 0.0 & - & 0.319 & 0.489 & 0.164 & 0.383 \\\\\n",
      "\\textbf{HRT}\n",
      "& abnormal (73\\%) & 0.0 & - & 0.61 & 0.111 & 0.095 & 0.695 & 0.648 & 0.183 & 0.646 \\\\\n",
      "& normal (26\\%) & 0.0 & - & 0.61 & 0.786 & 0.107 & 0.695 & 0.392 & 0.183 & 0.646 \\\\\n",
      "\\textbf{MI}\n",
      "& 1 (9\\%) & 0.528 & 0.194 & 0.694 & 0.443 & 0.252 & 0.777 & 0.456 & 0.241 & 0.812 \\\\\n",
      "& 10 (50\\%) & 0.503 & 0.202 & 0.694 & 0.458 & 0.251 & 0.777 & 0.573 & 0.244 & 0.812 \\\\\n",
      "& 2 (5\\%) & 0.449 & 0.209 & 0.694 & 0.426 & 0.269 & 0.777 & 0.395 & 0.251 & 0.812 \\\\\n",
      "& 3 (6\\%) & 0.475 & 0.214 & 0.694 & 0.505 & 0.188 & 0.777 & 0.545 & 0.226 & 0.812 \\\\\n",
      "& 4 (4\\%) & 0.0 & - & 0.694 & 0.44 & 0.247 & 0.777 & 0.487 & 0.227 & 0.812 \\\\\n",
      "& 5 (3\\%) & 0.464 & 0.211 & 0.694 & 0.332 & 0.224 & 0.777 & 0.427 & 0.25 & 0.812 \\\\\n",
      "& 6 (2\\%) & 0.619 & 0.214 & 0.694 & 0.555 & 0.185 & 0.777 & 0.503 & 0.167 & 0.812 \\\\\n",
      "& 7 (4\\%) & 0.522 & 0.242 & 0.694 & 0.386 & 0.278 & 0.777 & 0.381 & 0.224 & 0.812 \\\\\n",
      "& 8 (2\\%) & 0.0 & - & 0.694 & 0.365 & 0.169 & 0.777 & 0.429 & 0.247 & 0.812 \\\\\n",
      "& 9 (10\\%) & 0.621 & 0.073 & 0.694 & 0.46 & 0.167 & 0.777 & 0.51 & 0.188 & 0.812 \\\\\n",
      "\\textbf{ND}\n",
      "& 0 (16\\%) & 0.777 & 0.114 & 0.366 & 0.735 & 0.232 & 1.0 & 0.597 & 0.071 & 1.0 \\\\\n",
      "& 1 (35\\%) & 0.263 & 0.114 & 0.366 & 0.247 & 0.171 & 1.0 & 0.443 & 0.071 & 1.0 \\\\\n",
      "& 2 (47\\%) & 0.0 & - & 0.366 & 0.465 & 0.086 & 1.0 & 0.237 & 0.028 & 1.0 \\\\\n",
      "\\textbf{TECG}\n",
      "& 1 (50\\%) & 0.431 & 0.143 & 0.991 & 0.277 & 0.199 & 0.974 & 0.527 & 0.137 & 1.0 \\\\\n",
      "& 2 (49\\%) & 0.609 & 0.143 & 0.991 & 0.632 & 0.281 & 0.974 & 0.445 & 0.136 & 1.0 \\\\\n",
      "\\textbf{TOE}\n",
      "& 0 (50\\%) & 0.515 & 0.252 & 0.796 & 0.504 & 0.216 & 0.963 & 0.556 & 0.14 & 0.963 \\\\\n",
      "& 1 (49\\%) & 0.525 & 0.252 & 0.796 & 0.468 & 0.192 & 0.963 & 0.484 & 0.14 & 0.963 \\\\\n",
      "\\midrule\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('results/final_results.csv')\n",
    "\n",
    "# Define mappings for shortening dataset names\n",
    "dataset_mapping = {\n",
    "    \"AtrialFibrillation\": \"AF\",\n",
    "    \"CinCECGTorso\": \"CET\",\n",
    "    \"Colposcopy\": \"COL\",\n",
    "    \"ECG200\": \"ECG\",\n",
    "    \"ECG5000\": \"ECG5\",\n",
    "    \"EOGHorizontalSignal\": \"EOGH\",\n",
    "    \"EOGVerticalSignal\": \"EOGV\",\n",
    "    \"EMOPain\": \"EMO\",\n",
    "    \"Epilepsy\": \"EPI\",\n",
    "    \"EyesOpenShut\": \"EOS\",\n",
    "    \"HandMovementDirection\": \"HMD\",\n",
    "    \"Heartbeat\": \"HRT\",\n",
    "    \"MedicalImages\": \"MI\",\n",
    "    \"NerveDamage\": \"ND\",\n",
    "    \"ToeSegmentation1\": \"TOE\",\n",
    "    \"TwoLeadECG\": \"TECG\"\n",
    "}\n",
    "\n",
    "# Apply the mappings to shorten dataset names\n",
    "df['dataset'] = df['dataset'].map(dataset_mapping).fillna(df['dataset'])\n",
    "\n",
    "# Add percentage to class names\n",
    "df['class'] = df['class'].astype(str) + \" (\" + (df['class_perc'] * 100).astype(int).astype(str) + \"\\%)\"\n",
    "\n",
    "# Sort by dataset and class\n",
    "df = df.sort_values(by=['dataset', 'class'])\n",
    "\n",
    "# Initialize variables to track the current dataset\n",
    "current_dataset = None\n",
    "\n",
    "# Iterate through the dataset in chunks of 3 rows (one for each model)\n",
    "for i in range(0, len(df), 3):\n",
    "    # Get the 3 rows for the current class\n",
    "    lstm_row = df.iloc[i]\n",
    "    catch22_row = df.iloc[i + 1]\n",
    "    rocket_row = df.iloc[i + 2]\n",
    "\n",
    "    # Print dataset header if it changes\n",
    "    if lstm_row['dataset'] != current_dataset:\n",
    "        print(f\"\\\\textbf{{{lstm_row['dataset']}}}\")\n",
    "        current_dataset = lstm_row['dataset']\n",
    "\n",
    "    # Format values, replacing std of 0.0 with '-'\n",
    "    def format_value(value, std):\n",
    "        return f\"{round(value, 3)} & {round(std, 3) if std != 0.0 else '-'}\"\n",
    "\n",
    "    # Format the row\n",
    "    formatted_row = (\n",
    "        f\"& {lstm_row['class']} \"\n",
    "        f\"& {format_value(lstm_row['mean'], lstm_row['std'])} & {round(lstm_row['model_acc'], 3)} \"\n",
    "        f\"& {format_value(catch22_row['mean'], catch22_row['std'])} & {round(catch22_row['model_acc'], 3)} \"\n",
    "        f\"& {format_value(rocket_row['mean'], rocket_row['std'])} & {round(rocket_row['model_acc'], 3)} \\\\\\\\\"\n",
    "    )\n",
    "\n",
    "    # Print the formatted row\n",
    "    print(formatted_row)\n",
    "\n",
    "# Print a midrule at the end\n",
    "print(\"\\\\midrule\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\textbf{AF} & 0.0 & - & 0.0 & 0.0 & - & 0.333 & 0.0 & - & 0.0 \\\\\n",
      "\\textbf{CET} & 0.505 & 0.115 & 0.996 & 0.475 & 0.151 & 0.979 & 0.508 & 0.072 & 1.0 \\\\\n",
      "\\textbf{COL} & 0.072 & 0.027 & 0.45 & 0.19 & 0.078 & 0.425 & 0.165 & 0.029 & 0.3 \\\\\n",
      "\\textbf{ECG} & 0.52 & 0.081 & 0.85 & 0.475 & 0.145 & 0.8 & 0.52 & 0.125 & 0.95 \\\\\n",
      "\\textbf{ECG5} & 0.415 & 0.128 & 0.956 & 0.311 & 0.118 & 0.948 & 0.42 & 0.14 & 0.963 \\\\\n",
      "\\textbf{EMO} & 0.501 & 0.026 & 0.777 & 0.563 & 0.163 & 0.906 & 0.3 & 0.231 & 0.789 \\\\\n",
      "\\textbf{EOGH} & 0.15 & 0.089 & 0.262 & 0.352 & 0.224 & 0.786 & 0.446 & 0.199 & 0.89 \\\\\n",
      "\\textbf{EOGV} & 0.087 & 0.069 & 0.207 & 0.338 & 0.234 & 0.662 & 0.455 & 0.178 & 0.828 \\\\\n",
      "\\textbf{EOS} & 0.0 & - & 0.55 & 0.47 & 0.174 & 0.65 & 0.52 & 0.106 & 0.5 \\\\\n",
      "\\textbf{EPI} & 0.497 & 0.182 & 0.764 & 0.44 & 0.168 & 0.982 & 0.461 & 0.159 & 0.982 \\\\\n",
      "\\textbf{HMD} & 0.254 & 0.243 & 0.255 & 0.082 & 0.041 & 0.319 & 0.452 & 0.143 & 0.383 \\\\\n",
      "\\textbf{HRT} & 0.0 & - & 0.61 & 0.449 & 0.101 & 0.695 & 0.52 & 0.183 & 0.646 \\\\\n",
      "\\textbf{MI} & 0.418 & 0.156 & 0.694 & 0.437 & 0.223 & 0.777 & 0.47 & 0.226 & 0.812 \\\\\n",
      "\\textbf{ND} & 0.347 & 0.076 & 0.366 & 0.483 & 0.163 & 1.0 & 0.426 & 0.057 & 1.0 \\\\\n",
      "\\textbf{TECG} & 0.52 & 0.143 & 0.991 & 0.454 & 0.24 & 0.974 & 0.486 & 0.136 & 1.0 \\\\\n",
      "\\textbf{TOE} & 0.52 & 0.252 & 0.796 & 0.486 & 0.204 & 0.963 & 0.52 & 0.14 & 0.963 \\\\\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('results/final_results.csv')\n",
    "\n",
    "# Define mappings for shortening dataset names\n",
    "dataset_mapping = {\n",
    "    \"AtrialFibrillation\": \"AF\",\n",
    "    \"CinCECGTorso\": \"CET\",\n",
    "    \"Colposcopy\": \"COL\",\n",
    "    \"ECG200\": \"ECG\",\n",
    "    \"ECG5000\": \"ECG5\",\n",
    "    \"EOGHorizontalSignal\": \"EOGH\",\n",
    "    \"EOGVerticalSignal\": \"EOGV\",\n",
    "    \"EMOPain\": \"EMO\",\n",
    "    \"Epilepsy\": \"EPI\",\n",
    "    \"EyesOpenShut\": \"EOS\",\n",
    "    \"HandMovementDirection\": \"HMD\",\n",
    "    \"Heartbeat\": \"HRT\",\n",
    "    \"MedicalImages\": \"MI\",\n",
    "    \"NerveDamage\": \"ND\",\n",
    "    \"ToeSegmentation1\": \"TOE\",\n",
    "    \"TwoLeadECG\": \"TECG\"\n",
    "}\n",
    "\n",
    "# Apply the mappings to shorten dataset names\n",
    "df['dataset'] = df['dataset'].map(dataset_mapping).fillna(df['dataset'])\n",
    "\n",
    "# Add percentage to class names\n",
    "df['class'] = df['class'].astype(str) + \" (\" + (df['class_perc'] * 100).astype(int).astype(str) + \"\\%)\"\n",
    "\n",
    "# Sort by dataset and class\n",
    "df = df.sort_values(by=['dataset', 'class'])\n",
    "\n",
    "data_results = []\n",
    "\n",
    "# Now compute and print averages for each dataset and model\n",
    "unique_datasets = df['dataset'].unique()\n",
    "\n",
    "for dataset in unique_datasets:\n",
    "    dataset_df = df[df['dataset'] == dataset]\n",
    "    \n",
    "    # Calculate averages for each model\n",
    "    lstm_avg_mean = dataset_df[dataset_df['model'] == 'lstm']['mean'].mean()\n",
    "    lstm_avg_std = dataset_df[dataset_df['model'] == 'lstm']['std'].mean()\n",
    "    lstm_avg_acc = dataset_df[dataset_df['model'] == 'lstm']['model_acc'].mean()\n",
    "    \n",
    "    catch22_avg_mean = dataset_df[dataset_df['model'] == 'catch22']['mean'].mean()\n",
    "    catch22_avg_std = dataset_df[dataset_df['model'] == 'catch22']['std'].mean()\n",
    "    catch22_avg_acc = dataset_df[dataset_df['model'] == 'catch22']['model_acc'].mean()\n",
    "    \n",
    "    rocket_avg_mean = dataset_df[dataset_df['model'] == 'rocket']['mean'].mean()\n",
    "    rocket_avg_std = dataset_df[dataset_df['model'] == 'rocket']['std'].mean()\n",
    "    rocket_avg_acc = dataset_df[dataset_df['model'] == 'rocket']['model_acc'].mean()\n",
    "    \n",
    "    # Format the averages row\n",
    "    def format_avg_value(value, std):\n",
    "        return f\"{round(value, 3)} & {round(std, 3) if std != 0.0 else '-'}\"\n",
    "\n",
    "    formatted_avg_row = (\n",
    "        f\"\\\\textbf{{{dataset}}} \"\n",
    "        f\"& {format_avg_value(lstm_avg_mean, lstm_avg_std)} & {round(lstm_avg_acc, 3)} \"\n",
    "        f\"& {format_avg_value(catch22_avg_mean, catch22_avg_std)} & {round(catch22_avg_acc, 3)} \"\n",
    "        f\"& {format_avg_value(rocket_avg_mean, rocket_avg_std)} & {round(rocket_avg_acc, 3)} \\\\\\\\\"\n",
    "    )\n",
    "    \n",
    "    row = [lstm_avg_mean, lstm_avg_std, lstm_avg_acc,\n",
    "           catch22_avg_mean, catch22_avg_std, catch22_avg_acc,\n",
    "           rocket_avg_mean, rocket_avg_std, rocket_avg_acc]\n",
    "    \n",
    "    data_results.append(row)\n",
    "    print(formatted_avg_row)\n",
    "\n",
    "\n",
    "columns = ['LSTM Mean', 'LSTM Std', 'LSTM Acc',\n",
    "           'Catch22 Mean', 'Catch22 Std', 'Catch22 Acc',\n",
    "           'ROCKET Mean', 'ROCKET Std', 'ROCKET Acc']\n",
    "\n",
    "df_results = pd.DataFrame(data_results, columns=columns)\n",
    "df_results.to_csv('results/average_results.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "morph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
