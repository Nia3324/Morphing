{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{tabular}{l c c c}\n",
      "\\toprule\n",
      "\\textbf{Dataset} & \\textbf{Train Shape} & \\textbf{Test Shape} & \\textbf{\\# Classes} \\\\\n",
      "\\midrule\n",
      "AtrialFibrillation (AF) & (19, 2, 640) & (5, 2, 640) & 3 \\\\\n",
      "CinCECGTorso (CET) & (908, 1, 1639) & (228, 1, 1639) & 4 \\\\\n",
      "ECG200 (ECG2) & (128, 1, 96) & (32, 1, 96) & 2 \\\\\n",
      "ECGFiveDays (ECG5) & (565, 1, 136) & (142, 1, 136) & 2 \\\\\n",
      "EMOPain (EMO) & (846, 30, 200) & (212, 30, 200) & 3 \\\\\n",
      "Epilepsy (EPI) & (176, 3, 206) & (44, 3, 206) & 4 \\\\\n",
      "EyesOpenShut (EOS) & (62, 14, 128) & (16, 14, 128) & 2 \\\\\n",
      "HandMovementDirection (HMD) & (149, 10, 400) & (38, 10, 400) & 4 \\\\\n",
      "Heartbeat (HRT) & (261, 61, 405) & (66, 61, 405) & 2 \\\\\n",
      "MedicalImages (MI) & (729, 1, 99) & (183, 1, 99) & 10 \\\\\n",
      "NerveDamage (ND) & (130, 1, 1500) & (33, 1, 1500) & 3 \\\\\n",
      "TwoLeadECG (TECG) & (743, 1, 82) & (186, 1, 82) & 2 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('final_results/experiments_results.csv')\n",
    "\n",
    "# Define mappings for shortening dataset names\n",
    "dataset_mapping = {\n",
    "    \"AtrialFibrillation\": \"AF\",\n",
    "    \"CinCECGTorso\": \"CET\",\n",
    "    \"ECG200\": \"ECG2\",\n",
    "    \"ECGFiveDays\": \"ECG5\",\n",
    "    \"EMOPain\": \"EMO\",\n",
    "    \"Epilepsy\": \"EPI\",\n",
    "    \"EyesOpenShut\": \"EOS\",\n",
    "    \"HandMovementDirection\": \"HMD\",\n",
    "    \"Heartbeat\": \"HRT\",\n",
    "    \"MedicalImages\": \"MI\",\n",
    "    \"NerveDamage\": \"ND\",\n",
    "    \"TwoLeadECG\": \"TECG\",\n",
    "}\n",
    "\n",
    "# Group by dataset to get unique datasets\n",
    "grouped = df.groupby('dataset').first().reset_index()\n",
    "\n",
    "# Initialize a list to store table rows\n",
    "table_rows = []\n",
    "\n",
    "# Iterate over each dataset\n",
    "for _, row in grouped.iterrows():\n",
    "    dataset_name = row['dataset']\n",
    "    # Add the shortened name in parentheses\n",
    "    shortened_name = dataset_mapping.get(dataset_name, dataset_name)  # Use original name if no mapping exists\n",
    "    dataset_name_formatted = f\"{dataset_name} ({shortened_name})\"\n",
    "    \n",
    "    n_variates = int(row['n_variates'])  # Number of variates (e.g., 1 for univariate)\n",
    "    ts_length = int(row['ts_length'])    # Time series length\n",
    "    n_classes = int(row['n_classes'])    # Number of classes\n",
    "    \n",
    "    # Calculate train and test sizes (80/20 split)\n",
    "    total_samples = int(row['df_size'])\n",
    "    train_size = int(total_samples * 0.8)\n",
    "    test_size = total_samples - train_size\n",
    "    \n",
    "    # Format train and test shapes\n",
    "    train_shape = f\"({train_size}, {n_variates}, {ts_length})\"\n",
    "    test_shape = f\"({test_size}, {n_variates}, {ts_length})\"\n",
    "    \n",
    "    # Append to table rows\n",
    "    table_rows.append([dataset_name_formatted, train_shape, test_shape, n_classes])\n",
    "\n",
    "# Generate the LaTeX table\n",
    "latex_table = \"\"\"\n",
    "\\\\begin{tabular}{l c c c}\n",
    "\\\\toprule\n",
    "\\\\textbf{Dataset} & \\\\textbf{Train Shape} & \\\\textbf{Test Shape} & \\\\textbf{\\\\# Classes} \\\\\\\\\n",
    "\\\\midrule\n",
    "\"\"\"\n",
    "\n",
    "# Add rows to the table\n",
    "for row in table_rows:\n",
    "    latex_table += f\"{row[0]} & {row[1]} & {row[2]} & {row[3]} \\\\\\\\\\n\"\n",
    "\n",
    "# Close the table\n",
    "latex_table += \"\"\"\\\\bottomrule\n",
    "\\\\end{tabular}\n",
    "\"\"\"\n",
    "\n",
    "# Print the LaTeX table\n",
    "print(latex_table)\n",
    "\n",
    "# Optionally, save the table to a .tex file\n",
    "with open('dataset_table.tex', 'w') as f:\n",
    "    f.write(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(['n', 's', 't'], dtype='<U1'), array([10, 10, 10], dtype=int64))\n",
      "(30, 2, 640)\n",
      "[[-0.02964  0.00988  0.00988 ... -0.13832 -0.15314 -0.1482 ]\n",
      " [ 0.      -0.00988 -0.02964 ...  0.08892  0.0988   0.0988 ]]\n",
      "[[ 0.66445  1.1645   1.0001  ... -0.0411  -0.1918  -0.1233 ]\n",
      " [ 0.02684  0.08723 -0.16775 ...  0.01342 -0.00671  0.00671]]\n",
      "[[ 0.07686  0.06588  0.02196 ... -0.08784 -0.09333 -0.07137]\n",
      " [ 0.1309   0.1309   0.0952  ... -0.05355 -0.04165 -0.01785]]\n",
      "[[-0.2091  -0.2091  -0.204   ... -0.1938  -0.4131  -0.4233 ]\n",
      " [ 0.01104 -0.00552  0.      ... -0.02208  0.03312  0.11592]]\n",
      "[[-0.01482 -0.03458 -0.03458 ...  0.0494   0.13832  0.08398]\n",
      " [ 0.01482  0.01482  0.00494 ... -0.03952 -0.02964  0.00988]]\n",
      "[[-0.15314 -0.10374 -0.0494  ... -0.1482  -0.13338 -0.12844]\n",
      " [ 0.00988  0.01482  0.04446 ...  0.15314  0.0988   0.03952]]\n",
      "[[-0.05391 -0.06589 -0.08386 ...  0.09584  0.11381  0.09584]\n",
      " [ 0.27166  0.30056  0.3179  ...  0.15028  0.2023   0.2312 ]]\n",
      "[[ 0.12844  0.12844  0.16302 ... -0.10868 -0.09386 -0.08398]\n",
      " [ 0.05928  0.05928  0.0494  ...  0.08892  0.10374  0.11362]]\n",
      "[[-0.08398 -0.08398 -0.06916 ... -0.06422 -0.0494  -0.01482]\n",
      " [-0.01482  0.      -0.02964 ...  0.01976  0.00494  0.01482]]\n",
      "[[-0.05928 -0.04446 -0.05434 ... -0.10868 -0.10868 -0.09386]\n",
      " [ 0.00988  0.00494  0.00988 ...  0.03458  0.03952  0.03458]]\n",
      "----------------------------------------------------------------------\n",
      "[[-0.1235  -0.11856 -0.13832 ...  0.10374  0.12844  0.15314]\n",
      " [ 0.11362  0.11362  0.10374 ...  0.01482  0.01482  0.00988]]\n",
      "[[ 0.05434  0.00988  0.03952 ... -0.04446 -0.10868 -0.06916]\n",
      " [ 0.00988  0.01976  0.00988 ...  0.01976  0.00988  0.00494]]\n",
      "[[ 0.02964 -0.06916 -0.10374 ... -0.07904 -0.16796 -0.03458]\n",
      " [ 0.18278  0.12844  0.10374 ...  0.02964  0.0247   0.0247 ]]\n",
      "[[ 0.22762  0.29351  0.20366 ... -0.25158 -0.02995  0.2396 ]\n",
      " [-0.93636 -0.4335  -0.13294 ... -2.0114  -2.023   -1.1155 ]]\n",
      "[[-0.0741  -0.04446 -0.07904 ... -0.06916 -0.06916 -0.07904]\n",
      " [ 0.06422  0.06916  0.0494  ...  0.09386  0.08398  0.08892]]\n",
      "[[ 0.00988  0.       0.00988 ...  0.10868  0.42484  0.71136]\n",
      " [-0.01482 -0.01482 -0.02964 ... -0.04446 -0.16302 -0.15808]]\n",
      "[[-0.1224  -0.1326  -0.1326  ... -0.1479  -0.1428  -0.1428 ]\n",
      " [-0.01104 -0.0276   0.01104 ... -0.03864 -0.04416 -0.06072]]\n",
      "[[-0.03425 -0.03425 -0.02055 ... -0.0274  -0.0137  -0.0274 ]\n",
      " [-0.04026 -0.03355 -0.04026 ... -0.00671 -0.00671  0.00671]]\n",
      "[[-0.10868 -0.11856 -0.16302 ... -0.08892 -0.08398 -0.0988 ]\n",
      " [ 0.05434  0.05928  0.06422 ...  0.08892  0.09386  0.07904]]\n",
      "[[-0.07137 -0.01647 -0.01098 ...  0.07137  0.04392  0.     ]\n",
      " [ 0.10115  0.08925  0.08925 ...  0.05355  0.0238   0.01785]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from aeon.datasets import load_classification\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = 'AtrialFibrillation'\n",
    "X, y = load_classification(data)\n",
    "\n",
    "print(np.unique(y, return_counts=True))\n",
    "print(X.shape)\n",
    "\n",
    "for x in X[y=='s']:\n",
    "    print(x)\n",
    "\n",
    "\n",
    "print(\"-\"*70)\n",
    "\n",
    "for x in X[y=='t']:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\textbf{AF}\n",
      "& n (33\\%) & 0.0 & - & 0.0 & 0.0 & - & 0.333 & 0.0 & - & 0.0 \\\\\n",
      "& s (29\\%) & 0.0 & - & 0.0 & 0.0 & - & 0.333 & 0.0 & - & 0.0 \\\\\n",
      "\\textbf{CET}\n",
      "& 1 (24\\%) & 0.566 & 0.117 & 0.996 & 0.499 & 0.142 & 0.986 & 0.536 & 0.102 & 1.0 \\\\\n",
      "& 2 (25\\%) & 0.51 & 0.109 & 0.996 & 0.442 & 0.135 & 0.986 & 0.489 & 0.089 & 1.0 \\\\\n",
      "& 3 (25\\%) & 0.524 & 0.115 & 0.996 & 0.448 & 0.147 & 0.986 & 0.489 & 0.1 & 1.0 \\\\\n",
      "& 4 (24\\%) & 0.419 & 0.101 & 0.996 & 0.456 & 0.145 & 0.986 & 0.431 & 0.083 & 1.0 \\\\\n",
      "\\textbf{ECG2}\n",
      "& -1 (33\\%) & 0.406 & 0.16 & 0.875 & 0.254 & 0.18 & 0.825 & 0.44 & 0.14 & 0.95 \\\\\n",
      "& 1 (66\\%) & 0.614 & 0.16 & 0.875 & 0.69 & 0.207 & 0.825 & 0.58 & 0.14 & 0.95 \\\\\n",
      "\\textbf{ECG5}\n",
      "& 1 (50\\%) & 0.442 & 0.135 & 1.0 & 0.644 & 0.127 & 0.989 & 0.531 & 0.061 & 1.0 \\\\\n",
      "& 2 (49\\%) & 0.578 & 0.135 & 1.0 & 0.346 & 0.104 & 0.989 & 0.489 & 0.061 & 1.0 \\\\\n",
      "\\textbf{EMO}\n",
      "& 0 (77\\%) & 0.302 & 0.165 & 0.815 & 0.176 & 0.132 & 0.925 & 0.556 & 0.353 & 0.808 \\\\\n",
      "& 1 (14\\%) & 0.651 & 0.267 & 0.815 & 0.725 & 0.214 & 0.925 & 0.304 & 0.307 & 0.808 \\\\\n",
      "& 2 (8\\%) & 0.755 & 0.14 & 0.815 & 0.854 & 0.197 & 0.925 & 0.0 & - & 0.808 \\\\\n",
      "\\textbf{EOS}\n",
      "& 0 (55\\%) & 0.0 & - & 0.55 & 0.198 & 0.162 & 0.6 & 0.478 & 0.278 & 0.5 \\\\\n",
      "& 1 (44\\%) & 0.0 & - & 0.55 & 0.752 & 0.264 & 0.6 & 0.308 & 0.185 & 0.5 \\\\\n",
      "\\textbf{EPI}\n",
      "& epilepsy (24\\%) & 0.551 & 0.232 & 0.764 & 0.567 & 0.159 & 0.964 & 0.538 & 0.218 & 0.982 \\\\\n",
      "& running (26\\%) & 0.498 & 0.214 & 0.764 & 0.378 & 0.172 & 0.964 & 0.298 & 0.076 & 0.982 \\\\\n",
      "& sawing (21\\%) & 0.632 & 0.122 & 0.764 & 0.449 & 0.161 & 0.964 & 0.456 & 0.157 & 0.982 \\\\\n",
      "& walking (27\\%) & 0.354 & 0.149 & 0.764 & 0.424 & 0.165 & 0.964 & 0.56 & 0.206 & 0.982 \\\\\n",
      "\\textbf{HMD}\n",
      "& backward (22\\%) & 0.54 & 0.06 & 0.298 & 0.145 & 0.2 & 0.34 & 0.0 & - & 0.34 \\\\\n",
      "& forward (31\\%) & 0.232 & 0.351 & 0.298 & 0.0 & - & 0.34 & 0.19 & - & 0.34 \\\\\n",
      "& left (24\\%) & 0.187 & 0.133 & 0.298 & 0.02 & 0.01 & 0.34 & 0.0 & - & 0.34 \\\\\n",
      "& right (22\\%) & 0.535 & 0.251 & 0.298 & 0.02 & 0.008 & 0.34 & 0.83 & - & 0.34 \\\\\n",
      "\\textbf{HRT}\n",
      "& abnormal (73\\%) & 0.0 & - & 0.622 & 0.023 & 0.018 & 0.72 & 0.522 & 0.211 & 0.671 \\\\\n",
      "& normal (26\\%) & 0.0 & - & 0.622 & 0.684 & 0.336 & 0.72 & 0.518 & 0.211 & 0.671 \\\\\n",
      "\\textbf{MI}\n",
      "& 1 (9\\%) & 0.529 & 0.22 & 0.686 & 0.434 & 0.256 & 0.773 & 0.443 & 0.241 & 0.808 \\\\\n",
      "& 10 (50\\%) & 0.477 & 0.211 & 0.686 & 0.383 & 0.225 & 0.773 & 0.456 & 0.241 & 0.808 \\\\\n",
      "& 2 (5\\%) & 0.447 & 0.243 & 0.686 & 0.509 & 0.267 & 0.773 & 0.437 & 0.206 & 0.808 \\\\\n",
      "& 3 (6\\%) & 0.471 & 0.232 & 0.686 & 0.487 & 0.173 & 0.773 & 0.558 & 0.208 & 0.808 \\\\\n",
      "& 4 (4\\%) & 0.0 & - & 0.686 & 0.326 & 0.208 & 0.773 & 0.496 & 0.191 & 0.808 \\\\\n",
      "& 5 (3\\%) & 0.413 & 0.221 & 0.686 & 0.326 & 0.215 & 0.773 & 0.433 & 0.207 & 0.808 \\\\\n",
      "& 6 (2\\%) & 0.554 & 0.171 & 0.686 & 0.561 & 0.179 & 0.773 & 0.559 & 0.145 & 0.808 \\\\\n",
      "& 7 (4\\%) & 0.465 & 0.245 & 0.686 & 0.369 & 0.251 & 0.773 & 0.39 & 0.205 & 0.808 \\\\\n",
      "& 8 (2\\%) & 0.0 & - & 0.686 & 0.329 & 0.216 & 0.773 & 0.442 & 0.28 & 0.808 \\\\\n",
      "& 9 (10\\%) & 0.0 & - & 0.686 & 0.445 & 0.216 & 0.773 & 0.6 & 0.245 & 0.808 \\\\\n",
      "\\textbf{ND}\n",
      "& 0 (16\\%) & 0.0 & - & 0.415 & 0.796 & 0.16 & 1.0 & 0.33 & 0.111 & 1.0 \\\\\n",
      "& 1 (35\\%) & 0.0 & - & 0.415 & 0.221 & 0.139 & 1.0 & 0.652 & 0.099 & 1.0 \\\\\n",
      "& 2 (47\\%) & 0.0 & - & 0.415 & 0.476 & 0.095 & 1.0 & 0.491 & 0.061 & 1.0 \\\\\n",
      "\\textbf{TECG}\n",
      "& 1 (50\\%) & 0.414 & 0.161 & 0.991 & 0.287 & 0.178 & 0.983 & 0.53 & 0.129 & 1.0 \\\\\n",
      "& 2 (49\\%) & 0.606 & 0.161 & 0.991 & 0.672 & 0.215 & 0.983 & 0.452 & 0.119 & 1.0 \\\\\n",
      "\\midrule\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"final_results/experiments_results.csv\")  # Replace with your file path\n",
    "\n",
    "# Define mappings for shortening dataset and class names\n",
    "dataset_mapping = {\n",
    "    \"AtrialFibrillation\": \"AF\",\n",
    "    \"CinCECGTorso\": \"CET\",\n",
    "    \"ECG200\": \"ECG2\",\n",
    "    \"ECGFiveDays\": \"ECG5\",\n",
    "    \"EMOPain\": \"EMO\",\n",
    "    \"Epilepsy\": \"EPI\",\n",
    "    \"EyesOpenShut\": \"EOS\",\n",
    "    \"HandMovementDirection\": \"HMD\",\n",
    "    \"Heartbeat\": \"HRT\",\n",
    "    \"MedicalImages\": \"MI\",\n",
    "    \"NerveDamage\": \"ND\",\n",
    "    \"TwoLeadECG\": \"TECG\",\n",
    "}\n",
    "\n",
    "# Apply the mappings to shorten dataset names\n",
    "df['dataset'] = df['dataset'].map(dataset_mapping).fillna(df['dataset'])\n",
    "\n",
    "# Add percentage to class names\n",
    "df['class'] = df['class'].astype(str) + \" (\" + (df['class_perc'] * 100).astype(int).astype(str) + \"\\%)\"\n",
    "\n",
    "# Sort by dataset and class\n",
    "df = df.sort_values(by=['dataset', 'class'])\n",
    "\n",
    "# Initialize variables to track the current dataset\n",
    "current_dataset = None\n",
    "\n",
    "# Iterate through the dataset in chunks of 3 rows (one for each model)\n",
    "for i in range(0, len(df), 3):\n",
    "    # Get the 3 rows for the current class\n",
    "    lstm_row = df.iloc[i]\n",
    "    catch22_row = df.iloc[i + 1]\n",
    "    rocket_row = df.iloc[i + 2]\n",
    "\n",
    "    # Print dataset header if it changes\n",
    "    if lstm_row['dataset'] != current_dataset:\n",
    "        print(f\"\\\\textbf{{{lstm_row['dataset']}}}\")\n",
    "        current_dataset = lstm_row['dataset']\n",
    "\n",
    "    # Format values, replacing std of 0.0 with '-'\n",
    "    def format_value(value, std):\n",
    "        return f\"{round(value, 3)} & {round(std, 3) if std != 0.0 else '-'}\"\n",
    "\n",
    "    # Format the row\n",
    "    formatted_row = (\n",
    "        f\"& {lstm_row['class']} \"\n",
    "        f\"& {format_value(lstm_row['mean'], lstm_row['std'])} & {round(lstm_row['model_acc'], 3)} \"\n",
    "        f\"& {format_value(catch22_row['mean'], catch22_row['std'])} & {round(catch22_row['model_acc'], 3)} \"\n",
    "        f\"& {format_value(rocket_row['mean'], rocket_row['std'])} & {round(rocket_row['model_acc'], 3)} \\\\\\\\\"\n",
    "    )\n",
    "\n",
    "    # Print the formatted row\n",
    "    print(formatted_row)\n",
    "\n",
    "# Print a midrule at the end\n",
    "print(\"\\\\midrule\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MIST",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
