{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the class\n",
    "# from mitbhi_dataset import MITBIHDataset, SUBJECTS\n",
    "\n",
    "# # Initialize the dataset loader\n",
    "# dataset = MITBIHDataset(\n",
    "#     lead_index=0,          # Use the first ECG lead\n",
    "#     apply_filter=True,     # Apply bandpass filtering\n",
    "#     subjects=SUBJECTS,     # Use all subjects\n",
    "#     subsets=\"aami\"         # Use AAMI annotations\n",
    "# )\n",
    "\n",
    "# # Load the data\n",
    "# X, y, s = dataset.load_data()\n",
    "\n",
    "# # reshape the data to (n,1,m)\n",
    "# X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\n",
    "# # X: ECG segments (features)\n",
    "# # y: Labels (AAMI classes)\n",
    "# # s: Subject IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Processed MIT-BIH Arrhythmia Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-17 12:29:20.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.mitbhi_dataset\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m120\u001b[0m - \u001b[1mDataset loaded from pickle file.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from source.mitbhi_dataset import MITBIHDataset, SUBJECTS\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "dataset = MITBIHDataset()\n",
    "X, y, s = dataset.load_data()\n",
    "\n",
    "# reshape the data to (n,1,m)\n",
    "X = X.reshape(X.shape[0], 1, X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, test_idx = next(splitter.split(X, y, s))\n",
    "\n",
    "X_train, X_test = X[train_idx], X[test_idx]\n",
    "y_train, y_test = y[train_idx], y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86919, 1, 180)\n",
      "(22480, 1, 180)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from source.models import Models\n",
    "from source.morph import Morph\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name = 'MITBIH'\n",
    "\n",
    "# Initialize variables to store results\n",
    "results_array = np.empty((0, 10)) \n",
    "results = {}\n",
    "\n",
    "# Save Dataset Features\n",
    "ts_length = X_train.shape[2]\n",
    "df_size = X_train.shape[0]\n",
    "n_classes = len(np.unique(y))  \n",
    "class_counts = Counter(y_train)\n",
    "num_classes = len(class_counts)\n",
    "\n",
    "# Train Models\n",
    "start = time.time()\n",
    "lstm = Models('lstm', X_train, y_train)\n",
    "lstm.train_lstm()\n",
    "catch = Models('catch22', X_train, y_train)\n",
    "catch.train_catch22()\n",
    "rocket = Models('rocket', X_train, y_train)\n",
    "rocket.train_rocket()\n",
    "\n",
    "\n",
    "training_time = time.time()\n",
    "print(f'Training time: {training_time - start}')\n",
    "\n",
    "# Evaluate models\n",
    "models = (lstm, catch, rocket)\n",
    "acc = {}\n",
    "for m in models:\n",
    "    pred, _ = m.predict(X_test)\n",
    "    acc[m.model_name] = accuracy_score(pred, y_test)\n",
    "\n",
    "# Loop through each class\n",
    "for c in np.unique(y):\n",
    "    start_class = time.time()\n",
    "    print(f'Processing Class: {c}')\n",
    "\n",
    "    # Calculate class percentage\n",
    "    class_perc = round(class_counts[c] / df_size, 3)\n",
    "\n",
    "    # Perform morphing calculations\n",
    "    mor = Morph(X_test, y_test, c)\n",
    "    mor.get_DTWGlobalBorderline(perc_samples=0.1)\n",
    "    res = mor.Binary_MorphingCalculater(models)\n",
    "\n",
    "    end_class = time.time()\n",
    "    print(f'Total Class {c} run time: {end_class - start_class}')\n",
    "\n",
    "    # Store results for the class\n",
    "    results[c] = res\n",
    "\n",
    "    # Append results to NumPy array\n",
    "    for model in res.keys():\n",
    "        data = res[model]['metrics']\n",
    "        line = np.array([[df_name, df_size, ts_length, n_classes, c, class_perc, model, data['mean'], data['std'], acc[model]]])\n",
    "        results_array = np.vstack((results_array, line))\n",
    "        \n",
    "\n",
    "# Save results for the current dataset\n",
    "file_name = f'results/pickles/{df_name}.pkl'\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "# Clean ups\n",
    "del models, lstm, catch, rocket, results\n",
    "\n",
    "# Convert NumPy array to Pandas DataFrame\n",
    "columns = ['dataset', 'df_size', 'ts_length', 'n_classes', 'class', 'class_perc', 'model', 'mean', 'std', 'model_acc']\n",
    "dataframe = pd.DataFrame(results_array, columns=columns)\n",
    "# Save results to CSV\n",
    "dataframe.to_csv('results/use_case.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "morph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
