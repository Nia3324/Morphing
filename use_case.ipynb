{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from source.models import Models\n",
    "from source.morph import Morph\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "from source.mitbhi_dataset import MITBIHDataset\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Processed MIT-BIH Arrhythmia Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the class\n",
    "# from source.mitbhi_dataset import MITBIHDataset, SUBJECTS\n",
    "# # Initialize the dataset loader\n",
    "# dataset = MITBIHDataset(\n",
    "#     lead_index=0,          # Use the first ECG lead\n",
    "#     apply_filter=True,     # Apply bandpass filtering\n",
    "#     subjects=SUBJECTS,     # Use all subjects\n",
    "#     subsets=\"aami\"         # Use AAMI annotations\n",
    "# )\n",
    "# # Load the data\n",
    "# X, y, s = dataset.load_data()\n",
    "# # reshape the data to (n,1,m)\n",
    "# X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "# # X: ECG segments (features)\n",
    "# # y: Labels (AAMI classes)\n",
    "# # s: Subject IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-18 17:40:08.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.mitbhi_dataset\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m120\u001b[0m - \u001b[1mDataset loaded from pickle file.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dataset = MITBIHDataset()\n",
    "X, y, s = dataset.load_data()\n",
    "\n",
    "# reshape the data to (n,1,m)\n",
    "X = X.reshape(X.shape[0], 1, X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = GroupShuffleSplit(n_splits=1, test_size=0.01, random_state=42)\n",
    "train_idx, test_idx = next(splitter.split(X, y, s))\n",
    "\n",
    "X_train, X_test = X[train_idx], X[test_idx]\n",
    "y_train, y_test = y[train_idx], y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Shape: (106744, 1, 180)\n",
      "X_test Shape: (2655, 1, 180)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train Shape:\", X_train.shape)\n",
    "print(\"X_test Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 11.9 GiB for an array with shape (1600300011,) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m catch\u001b[38;5;241m.\u001b[39mtrain_catch22()\n\u001b[0;32m      7\u001b[0m rocket \u001b[38;5;241m=\u001b[39m Models(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrocket\u001b[39m\u001b[38;5;124m'\u001b[39m, X_train, y_train)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mrocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_rocket\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anton\\Desktop\\Research\\Morphing\\source\\models.py:173\u001b[0m, in \u001b[0;36mModels.train_rocket\u001b[1;34m(self, n_kernels)\u001b[0m\n\u001b[0;32m    171\u001b[0m X_train_trasform \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrocket_kernels\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train)\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m RidgeClassifierCV(alphas\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mlogspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_trasform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anton\\anaconda3\\envs\\MIST\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\anton\\anaconda3\\envs\\MIST\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:2882\u001b[0m, in \u001b[0;36mRidgeClassifierCV.fit\u001b[1;34m(self, X, y, sample_weight, **params)\u001b[0m\n\u001b[0;32m   2876\u001b[0m \u001b[38;5;66;03m# If cv is None, gcv mode will be used and we used the binarized Y\u001b[39;00m\n\u001b[0;32m   2877\u001b[0m \u001b[38;5;66;03m# since y will not be binarized in _RidgeGCV estimator.\u001b[39;00m\n\u001b[0;32m   2878\u001b[0m \u001b[38;5;66;03m# If cv is not None, a GridSearchCV with some RidgeClassifier\u001b[39;00m\n\u001b[0;32m   2879\u001b[0m \u001b[38;5;66;03m# estimators are used where y will be binarized. Thus, we pass y\u001b[39;00m\n\u001b[0;32m   2880\u001b[0m \u001b[38;5;66;03m# instead of the binarized Y.\u001b[39;00m\n\u001b[0;32m   2881\u001b[0m target \u001b[38;5;241m=\u001b[39m Y \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m y\n\u001b[1;32m-> 2882\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, target, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m   2883\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\anton\\anaconda3\\envs\\MIST\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:2403\u001b[0m, in \u001b[0;36m_BaseRidgeCV.fit\u001b[1;34m(self, X, y, sample_weight, **params)\u001b[0m\n\u001b[0;32m   2392\u001b[0m         routed_params\u001b[38;5;241m.\u001b[39mscorer\u001b[38;5;241m.\u001b[39mscore[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[0;32m   2394\u001b[0m estimator \u001b[38;5;241m=\u001b[39m _RidgeGCV(\n\u001b[0;32m   2395\u001b[0m     alphas,\n\u001b[0;32m   2396\u001b[0m     fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2401\u001b[0m     alpha_per_target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha_per_target,\n\u001b[0;32m   2402\u001b[0m )\n\u001b[1;32m-> 2403\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2405\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2406\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2408\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2409\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha_ \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39malpha_\n\u001b[0;32m   2410\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_score_ \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mbest_score_\n",
      "File \u001b[1;32mc:\\Users\\anton\\anaconda3\\envs\\MIST\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:2134\u001b[0m, in \u001b[0;36m_RidgeGCV.fit\u001b[1;34m(self, X, y, sample_weight, score_params)\u001b[0m\n\u001b[0;32m   2131\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2132\u001b[0m     sqrt_sw \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(n_samples, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m-> 2134\u001b[0m X_mean, \u001b[38;5;241m*\u001b[39mdecomposition \u001b[38;5;241m=\u001b[39m \u001b[43mdecompose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msqrt_sw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2136\u001b[0m scorer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_scorer()\n\u001b[0;32m   2138\u001b[0m n_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\anton\\anaconda3\\envs\\MIST\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:2034\u001b[0m, in \u001b[0;36m_RidgeGCV._svd_decompose_design_matrix\u001b[1;34m(self, X, y, sqrt_sw)\u001b[0m\n\u001b[0;32m   2032\u001b[0m     intercept_column \u001b[38;5;241m=\u001b[39m sqrt_sw[:, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m   2033\u001b[0m     X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack((X, intercept_column))\n\u001b[1;32m-> 2034\u001b[0m U, singvals, _ \u001b[38;5;241m=\u001b[39m \u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2035\u001b[0m singvals_sq \u001b[38;5;241m=\u001b[39m singvals\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m   2036\u001b[0m UT_y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(U\u001b[38;5;241m.\u001b[39mT, y)\n",
      "File \u001b[1;32mc:\\Users\\anton\\anaconda3\\envs\\MIST\\lib\\site-packages\\scipy\\linalg\\_decomp_svd.py:160\u001b[0m, in \u001b[0;36msvd\u001b[1;34m(a, full_matrices, compute_uv, overwrite_a, check_finite, lapack_driver)\u001b[0m\n\u001b[0;32m    156\u001b[0m lwork \u001b[38;5;241m=\u001b[39m _compute_lwork(gesXd_lwork, a1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], a1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    157\u001b[0m                        compute_uv\u001b[38;5;241m=\u001b[39mcompute_uv, full_matrices\u001b[38;5;241m=\u001b[39mfull_matrices)\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# perform decomposition\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m u, s, v, info \u001b[38;5;241m=\u001b[39m \u001b[43mgesXd\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_uv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_uv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlwork\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_matrices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_a\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVD did not converge\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 11.9 GiB for an array with shape (1600300011,) and data type float64"
     ]
    }
   ],
   "source": [
    "# Train Models\n",
    "start = time.time()\n",
    "lstm = Models('lstm', X_train, y_train)\n",
    "lstm.train_lstm()\n",
    "catch = Models('catch22', X_train, y_train)\n",
    "catch.train_catch22()\n",
    "rocket = Models('rocket', X_train, y_train)\n",
    "rocket.train_rocket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = (lstm, catch, rocket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name = 'MITBIH'\n",
    "\n",
    "# Initialize variables to store results\n",
    "results_array = np.empty((0, 10)) \n",
    "results = {}\n",
    "\n",
    "# Save Dataset Features\n",
    "ts_length = X_train.shape[2]\n",
    "df_size = X_train.shape[0]\n",
    "n_classes = len(np.unique(y))  \n",
    "class_counts = Counter(y_train)\n",
    "num_classes = len(class_counts)\n",
    "\n",
    "\n",
    "\n",
    "training_time = time.time()\n",
    "print(f'Training time: {training_time - start}')\n",
    "\n",
    "# Evaluate models\n",
    "models = (lstm, catch, rocket)\n",
    "acc = {}\n",
    "for m in models:\n",
    "    pred, _ = m.predict(X_test)\n",
    "    acc[m.model_name] = accuracy_score(pred, y_test)\n",
    "\n",
    "# Loop through each class\n",
    "for c in np.unique(y):\n",
    "    start_class = time.time()\n",
    "    print(f'Processing Class: {c}')\n",
    "\n",
    "    # Calculate class percentage\n",
    "    class_perc = round(class_counts[c] / df_size, 3)\n",
    "\n",
    "    # Perform morphing calculations\n",
    "    mor = Morph(X_test, y_test, c)\n",
    "    mor.get_DTWGlobalBorderline(perc_samples=0.1)\n",
    "    res = mor.Binary_MorphingCalculater(models)\n",
    "\n",
    "    end_class = time.time()\n",
    "    print(f'Total Class {c} run time: {end_class - start_class}')\n",
    "\n",
    "    # Store results for the class\n",
    "    results[c] = res\n",
    "\n",
    "    # Append results to NumPy array\n",
    "    for model in res.keys():\n",
    "        data = res[model]['metrics']\n",
    "        line = np.array([[df_name, df_size, ts_length, n_classes, c, class_perc, model, data['mean'], data['std'], acc[model]]])\n",
    "        results_array = np.vstack((results_array, line))\n",
    "        \n",
    "\n",
    "# Save results for the current dataset\n",
    "file_name = f'results/pickles/{df_name}.pkl'\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "# Clean ups\n",
    "del models, lstm, catch, rocket, results\n",
    "\n",
    "# Convert NumPy array to Pandas DataFrame\n",
    "columns = ['dataset', 'df_size', 'ts_length', 'n_classes', 'class', 'class_perc', 'model', 'mean', 'std', 'model_acc']\n",
    "dataframe = pd.DataFrame(results_array, columns=columns)\n",
    "# Save results to CSV\n",
    "dataframe.to_csv('results/use_case.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MIST",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
